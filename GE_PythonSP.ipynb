{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57383f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(CURRENT_WAREHOUSE()='COMPUTE_WH', CURRENT_DATABASE()='TEST', CURRENT_SCHEMA()='VALIDATION')]\n"
     ]
    }
   ],
   "source": [
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.functions import udf, avg, col,lit,call_udf,countDistinct,sproc,udf\n",
    "from snowflake.snowpark.types import IntegerType, FloatType, StringType, BooleanType\n",
    "import pandas as pd\n",
    "from configs.config import snowflake_conn_prop_local as snowflake_conn_prop\n",
    "import sys\n",
    "import json\n",
    "import platform\n",
    "import os,requests\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from src.DataValidationContext import *\n",
    "from snowflake.snowpark import version\n",
    "\n",
    "session = Session.builder.configs(snowflake_conn_prop).create()\n",
    "\n",
    "print(session.sql('select current_warehouse(), current_database(), current_schema()').collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d6627092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading library from PyPI to ./temp/tarfiles ...\n",
      "Download complete: ./temp/tarfiles/great_expectations-0.15.14.tar.gz\n",
      "Started extracting GE tar file to ./temp/libs/ge ...\n",
      "Extracted great_expectations-0.15.14/great_expectations/render/notebook_assets/suite_edit/AUTHORING_INTRO.md to ./temp/libs/ge\n",
      "Done extracting GE tar file to ./temp/libs/ge\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "# Define project directories\n",
    "PROJECT_HOME_DIR = '.'\n",
    "LOCAL_TEMP_DIR = os.path.join(PROJECT_HOME_DIR, 'temp') \n",
    "LOCAL_LIB_DIR = os.path.join(LOCAL_TEMP_DIR, 'libs')\n",
    "LOCAL_TARFile_DIR = os.path.join(LOCAL_TEMP_DIR, 'tarfiles')\n",
    "\n",
    "# List of library URLs to download\n",
    "LIB_URLS = [\n",
    "    'https://files.pythonhosted.org/packages/8e/9d/cecb12289f7967b15facf550a0bbb9c1e910968c3a61b91fd8cdb80aeb3c/great_expectations-0.15.14.tar.gz'\n",
    "]\n",
    "\n",
    "for lib_url in LIB_URLS:\n",
    "    try:\n",
    "        # Get the file name from the URL\n",
    "        target_file = lib_url.split('/')[-1]\n",
    "        local_lib_fl = os.path.join(LOCAL_TARFile_DIR, target_file)\n",
    "        \n",
    "        # Create directories if they don't exist\n",
    "        Path(LOCAL_TARFile_DIR).mkdir(parents=True, exist_ok=True)\n",
    "        Path(LOCAL_LIB_DIR).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f'Downloading library from PyPI to {LOCAL_TARFile_DIR} ...')\n",
    "        with open(local_lib_fl, \"wb\") as f:\n",
    "            r = requests.get(lib_url, timeout=60)\n",
    "            r.raise_for_status()  # Check if the request was successful\n",
    "            f.write(r.content)\n",
    "        print(f'Download complete: {local_lib_fl}')\n",
    "        \n",
    "        # Function to extract specific files\n",
    "        def extract_specific_files(tar_file, target_dir, file_list=None):\n",
    "            with tarfile.open(tar_file, 'r:gz') as tar:\n",
    "                if file_list:\n",
    "                    for member in tar.getmembers():\n",
    "                        if any(member.name.endswith(file) for file in file_list):\n",
    "                            tar.extract(member, target_dir)\n",
    "                            print(f'Extracted {member.name} to {target_dir}')\n",
    "                else:\n",
    "                    tar.extractall(target_dir)\n",
    "                    print(f'Extracted all files to {target_dir}')\n",
    "        \n",
    "        # List of specific files you want to extract\n",
    "        files_to_extract = ['great_expectations/render/notebook_assets/suite_edit/AUTHORING_INTRO.md']\n",
    "        \n",
    "        print(f'Started extracting GE tar file to {LOCAL_LIB_DIR}/ge ...')\n",
    "        extract_specific_files(local_lib_fl, f'{LOCAL_LIB_DIR}/ge', files_to_extract)\n",
    "        print(f'Done extracting GE tar file to {LOCAL_LIB_DIR}/ge')\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error downloading the file: {e}\")\n",
    "    except tarfile.TarError as e:\n",
    "        print(f\"Error extracting the tar file: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a5e34f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./temp/libs/ge/great_expectations-0.15.14/great_expectations\n"
     ]
    }
   ],
   "source": [
    "# Getting the path for the great_expectation folder after the tar file is extracted.\n",
    "import glob\n",
    "ge_import_path=''\n",
    "for result in glob.iglob('./temp/libs/ge/great_expectations*'):\n",
    "    ge_import_path=result+'/great_expectations'\n",
    "print(ge_import_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b2dc59d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package 'great-expectations' in the local environment is 0.18.5, which does not fit the criteria for the requirement 'great-expectations'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'python-dotenv' in the local environment is 1.0.0, which does not fit the criteria for the requirement 'python-dotenv'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'pyparsing' in the local environment is 3.1.1, which does not fit the criteria for the requirement 'pyparsing'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "Package 'pycryptodomex' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "Package 'boto3' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "The version of package 'tqdm' in the local environment is 4.66.1, which does not fit the criteria for the requirement 'tqdm'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'ruamel.yaml' in the local environment is 0.17.17, which does not fit the criteria for the requirement 'ruamel.yaml'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'ipython' in the local environment is 8.18.1, which does not fit the criteria for the requirement 'ipython'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'mistune' in the local environment is 3.0.2, which does not fit the criteria for the requirement 'mistune'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "The version of package 'jsonschema' in the local environment is 4.20.0, which does not fit the criteria for the requirement 'jsonschema'. Your UDF might not work when the package version is different between the server and your local environment.\n",
      "Package 'sqlalchemy' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n",
      "Package 'chardet' is not installed in the local environment. Your UDF might not work when the package is installed on the server but not on your local environment.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "stage_location must be specified for permanent stored proc",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 29\u001b[0m\n\u001b[1;32m     17\u001b[0m session\u001b[38;5;241m.\u001b[39mclear_imports()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# session.add_import(ge_import_path)\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# session.add_import('src')\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# session.add_import('configs')\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;129;43m@sproc\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGEValidationResults\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m       \u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStringType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m       \u001b[49m\u001b[43minput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mStringType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mStringType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mStringType\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m       \u001b[49m\u001b[43mis_permanent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#    , stage_location='@phani_greatexpectation/ge_AllLibs')\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mgenerateGEValidationResults\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msession\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mSession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdb_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfrom\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mpathlib\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mimport\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPath\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mimport\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mos\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m,\u001b[39;49m\u001b[38;5;21;43;01msys\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m,\u001b[39;49m\u001b[38;5;21;43;01mjson\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m,\u001b[39;49m\u001b[38;5;21;43;01mtarfile\u001b[39;49;00m\u001b[38;5;241;43m,\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mdotenv\u001b[39;49;00m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gx-snowflake-Z1xK-j-2-py3.10/lib/python3.10/site-packages/snowflake/snowpark/stored_procedure.py:527\u001b[0m, in \u001b[0;36mStoredProcedureRegistration.register\u001b[0;34m(self, func, return_type, input_types, name, is_permanent, stage_location, imports, packages, replace, if_not_exists, parallel, execute_as, strict, external_access_integrations, secrets, statement_params, source_code_display, **kwargs)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid function: not a function or callable \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    523\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(__call__ is not defined): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(func)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m     )\n\u001b[1;32m    526\u001b[0m check_execute_as_arg(execute_as)\n\u001b[0;32m--> 527\u001b[0m \u001b[43mcheck_register_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTempObjectType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPROCEDURE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_permanent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# register stored procedure\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_register_sp(\n\u001b[1;32m    533\u001b[0m     func,\n\u001b[1;32m    534\u001b[0m     return_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    555\u001b[0m     force_inline_code\u001b[38;5;241m=\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforce_inline_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    556\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/gx-snowflake-Z1xK-j-2-py3.10/lib/python3.10/site-packages/snowflake/snowpark/_internal/udf_utils.py:349\u001b[0m, in \u001b[0;36mcheck_register_args\u001b[0;34m(object_type, name, is_permanent, stage_location, parallel)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    346\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname must be specified for permanent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_error_message_abbr(object_type)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    347\u001b[0m         )\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stage_location:\n\u001b[0;32m--> 349\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    350\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage_location must be specified for permanent \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mget_error_message_abbr(object_type)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m         )\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parallel \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m parallel \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m99\u001b[39m:\n\u001b[1;32m    354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSupported values of parallel are from 1 to 99, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparallel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    356\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: stage_location must be specified for permanent stored proc"
     ]
    }
   ],
   "source": [
    "from configs.config import snowflake_conn_prop_local as snowflake_conn_prop\n",
    "from src.DataValidationContext import GEDataValidationContext\n",
    "from src.BatchRequest import getBatchRequest\n",
    "from src.Expectations import  createExpectationSuite, createExpectations\n",
    "from src.RunLoadExpectations import runExpectaionValidation,loadValidationToDB\n",
    "from src.parsing import process_and_store_validation_results\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "session.sql(\"create or replace stage phani_greatexpectation\").collect()\n",
    "session.clear_packages()\n",
    "session.add_packages('great-expectations','packaging', 'python-dotenv', 'pyparsing', 'pandas', 'pycryptodomex', 'boto3', 'tzlocal', 'tqdm', 'requests', 'ruamel.yaml', 'ipython', 'jsonpatch', 'mistune', 'jinja2', 'jsonschema', 'scipy', 'altair', 'Click', 'colorama', 'cryptography', 'snowflake-snowpark-python', 'sqlalchemy', 'chardet', 'asn1crypto')\n",
    "session.clear_imports()\n",
    "# session.add_import(ge_import_path)\n",
    "# session.add_import('src')\n",
    "# session.add_import('configs')\n",
    "\n",
    "\n",
    "@sproc(session=session,name=\"GEValidationResults\", replace=True, \n",
    "       return_type=StringType(),\n",
    "       input_types=[StringType(),StringType(),StringType()],\n",
    "       is_permanent=True, stage_location='@phani_greatexpectation/ge_AllLibs')\n",
    "\n",
    "def generateGEValidationResults(session: Session, db_name: str, schema_name: str ,table_name: str) -> str:\n",
    "        \n",
    "    from pathlib import Path\n",
    "    import os ,sys ,json ,tarfile, dotenv\n",
    "    \n",
    "    expecationsuitename = \"expecationsuitename\"\n",
    "    checkpointname = \"checkpointname\"\n",
    "    \n",
    "    sftablename = f'{db_name}.VALIDATION.{schema_name}_{table_name}_VALIDATION_RAW'\n",
    "    destination_table  = f'{db_name}.VALIDATION.{schema_name}_{table_name}_VALIDATION_CLEAN'\n",
    "\n",
    "    #Creating GE context inside code\n",
    "    ge=GEDataValidationContext(table_name)\n",
    "    context=ge.getContext()\n",
    "\n",
    "    # convert all the date type columns into the same \n",
    "\n",
    "    desc_query = f\"DESC TABLE {db_name}.{schema_name}.{table_name}\"\n",
    "    columns_info = session.sql(desc_query).collect()\n",
    "    column_types = {row['name']: row['type'] for row in columns_info}\n",
    "    \n",
    "    select_clause = []\n",
    "    for col, col_type in column_types.items():\n",
    "        if 'DATE' in col_type or 'TIMESTAMP' in col_type:\n",
    "            select_clause.append(f\"TO_CHAR({col}, 'YYYY-MM-DD') AS {col}\")\n",
    "        else:\n",
    "            select_clause.append(col)\n",
    "    query = f\"SELECT {', '.join(select_clause)} FROM {db_name}.{schema_name}.{table_name}\"\n",
    "\n",
    "   # Execute the query and convert the results to a pandas DataFrame\n",
    "    pd_df = session.sql(query).to_pandas()\n",
    "\n",
    "\n",
    "    # Getting the batch request used while creating and running validation on expectations\n",
    "    local_batch_request=getBatchRequest(context,table_name,pd_df)\n",
    "    \n",
    "    #Creating GE expectation Suite\n",
    "    createExpectationSuite(context,expecationsuitename)\n",
    "\n",
    "    #Creating GE expecations\n",
    "    createExpectations(session, context,expecationsuitename,local_batch_request,pd_df, db_name,schema_name,table_name)\n",
    "\n",
    "    #Running GE validation \n",
    "    res=runExpectaionValidation(context,checkpointname,local_batch_request,expecationsuitename,table_name)\n",
    "    \n",
    "    #Loading validation result to Snowflake table.\n",
    "    loadValidationToDB(session,res,sftablename)\n",
    "\n",
    "\n",
    "    #Store the parsed data in a clean table\n",
    "    process_and_store_validation_results(session, sftablename, destination_table)\n",
    "\n",
    "    return f'VALIDATION RESULTS STORED IN {table_name}_VALIDATION_RAW & CLEAN DATA IN {table_name}_VALIDATION_CLEAN'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b015334",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling SP\n",
    "session.sql(\"call GEValidationResults('DATALAKE','GUS','USERS')\").collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
